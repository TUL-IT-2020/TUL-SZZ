# Zpětná propagace

> [!info] Back Propagation = BP. 
Pokud známe hodnotu gradientu v bodě A, je možné gradient pomocí derivace složené funkce (řetízkové pravidla) vyjádřit i pro prvek sítě B, který je blíže vstupu. V rámci učení se tak gradient šíří od výstupu směrem ke vstupu. 

> [!tip]
>Ve spojitosti se složenou derivací platí řetízkové pravidlo (chain rule).

## Zdroje:
- [What is backpropagation really doing? | Chapter 3, Deep learning](https://www.youtube.com/watch?v=Ilg3gGewQ5U)
- [Backpropagation calculus | Chapter 4, Deep learning](https://www.youtube.com/watch?v=tIeHLnjs5U8)