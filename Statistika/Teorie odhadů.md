# Teorie odhadÅ¯
## Definice: 
ğ‘¶ğ’…ğ’‰ğ’‚ğ’…ğ’†ğ’ ğ‘›ğ‘’ğ‘§ğ‘›Ã¡ğ‘šÃ©â„ğ‘œ ğ‘ğ‘ğ‘Ÿğ‘ğ‘šğ‘’ğ‘¡ğ‘Ÿğ‘¢ $\theta$ ğ‘›ğ‘ğ‘§ğ‘£ğ‘’ğ‘šğ‘’ ğ‘™ğ‘–ğ‘ğ‘œğ‘£ğ‘œğ‘™ğ‘›ğ‘œğ‘¢ ğ‘“ğ‘¢ğ‘›ğ‘˜ğ‘ğ‘– $\theta = ğ‘”(ğ‘‹_1, ğ‘‹_2, â€¦ , ğ‘‹_ğ‘›)$ , kterÃ¡ nezÃ¡visÃ­ na skuteÄnÃ© hodnotÄ› $\theta$. 

### PoznÃ¡mka: 
Odhad parametru mÅ¯Å¾e zÃ¡viset i na jinÃ½ch parametrech, pokud jsou znÃ¡mÃ©. 

$\hat \theta$ ... odhad
$\theta$ ... veliÄina

### PÅ™Ã­klady odhadÅ¯:
UvaÅ¾ujme nÃ¡hodnÃ½ vÃ½bÄ›r $ğ‘‹_1, ğ‘‹_2, â€¦ , ğ‘‹_ğ‘›$, kterÃ½ vznikl mÄ›Å™enÃ­m zaÅ¡umÄ›nÃ©ho stejnosmÄ›rnÃ©ho proudu. Matematicky lze model popsat jako $ğ‘‹_ğ‘– = ğ´ + ğ‘¤_ğ‘–$ , kde $A$ je konstantnÃ­ a $w_i\sim N(0,1)$ , tzv. bÃ­lÃ½ Å¡um. Ãškolem je odhadnout hodnotu $A$.
- Varianta 1: $\hat A = \frac{1}{n} \sum^{n}_{i=1} X_i$
- Varianta 2: $\hat A = X_1$
JakÃ½ odhad je lepÅ¡Ã­?

## Kvalita odhadu
### Definice:
ğ‘‚ğ‘‘â„ğ‘ğ‘‘ ğ‘›ğ‘’ğ‘§ğ‘›Ã¡ğ‘šÃ©â„ğ‘œ ğ‘ğ‘ğ‘Ÿğ‘ğ‘šğ‘’ğ‘¡ğ‘Ÿğ‘¢ $\theta$ ğ‘›ğ‘ğ‘§ğ‘£ğ‘’ğ‘šğ‘’ **ğ’ğ’†ğ’”ğ’•ğ’“ğ’‚ğ’ğ’Ã½**, ğ‘—ğ‘’ğ‘ ğ‘¡ğ‘™ğ‘–Å¾ğ‘’ ğ‘ğ‘™ğ‘ğ‘¡Ã­: $E[\hat \theta] = \theta$.
PoznÃ¡mka: Pokud odhad nenÃ­ nestrannÃ½, tzn. $E[\hat \theta] = \theta + b(\theta)$ , pak $b(\theta)$ nazveme bias, neboli **vychÃ½lenÃ­** odhadu.

### MVUE (= minimum variance unbiased estimator) 
Takto nazveme nestrannÃ½ odhad s minimÃ¡lnÃ­m rozptylem.

Pro ten platÃ­:
â€¢ NemusÃ­ vÅ¾dy existovat,
â€¢ Pokud existuje, mÅ¯Å¾e bÃ½t obtÃ­Å¾nÃ© ho najÃ­t,
â€¢ Rozptyl nestrannÃ©ho odhadu nemÅ¯Å¾e bÃ½t menÅ¡Ã­ neÅ¾ [[Rao-CramÃ©rova dolnÃ­ mez|CramÃ©rova-Raova dolnÃ­ mez (CRLB)]]

## VektorovÄ›
OdhadovanÃ½ parametr:
$$
\theta
= \begin{pmatrix}
\theta_1 \\\ 
... \\\ 
\theta_d 
\end{pmatrix}
$$
NapÅ™. $\theta = \begin{pmatrix} \mu \\\ \sigma^2 \end{pmatrix}$, tedy parametry NormÃ¡lnÃ­ho rozdÄ›lenÃ­, nebo odhad kovarianÄnÃ­ matice, lineÃ¡rnÃ­ regrese. UÅ¾ jsme vidÄ›li, Å¾e nestrannÃ½ odhad $\sigma^2$ se liÅ¡Ã­ v pÅ™Ã­padech, kdy (ne)znÃ¡me skuteÄnou hodnotu parametru $\mu$.
1. ZnÃ¡me $\mu$:
$$
\hat\sigma^2 = \frac{1}{N} \sum^N_{i=1} {(X_i - \mu)^2}
$$
2. NeznÃ¡me $\mu$ a nahradÃ­me ho vÃ½bÄ›rovÃ½m prÅ¯mÄ›rem:
$$
\hat\sigma^2 = \frac{1}{N-1} \sum^N_{i=1} {(X_i - \bar X_N)^2}
$$
